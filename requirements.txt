# FastAPI and server dependencies
fastapi>=0.115.2
uvicorn[standard]==0.24.0
python-multipart>=0.0.9

# PyTorch and related packages (CUDA 12.1 compatible)
torch==2.4.1
torchvision==0.19.1
torchaudio==2.4.1
xformers==0.0.28

# Audio processing
librosa==0.10.1
soundfile==0.12.1
scipy==1.11.4

# Image processing
Pillow==10.1.0
opencv-python>=4.9.0.80
imageio==2.33.1
imageio-ffmpeg==0.4.9

# Video processing
moviepy==1.0.3

# Deep learning and AI
transformers>=4.49.0
diffusers>=0.31.0
accelerate>=1.1.1
safetensors>=0.4.3

# Numerical computing
numpy>=1.23.5,<2
pandas==2.1.4

# Utilities
tqdm==4.66.1
omegaconf==2.3.0
einops==0.7.0
timm==0.9.12

# Flash attention alternatives (updated to fix compatibility):
# Option 1: Use xformers (already included) - preferred for most cases
# Option 2: Compatible flash-attn version for PyTorch 2.4.1
# Option 3: If flash-attn still fails, uncomment xformers alternative below

# Additional InfiniteTalk dependencies
misaki[en]
ninja
packaging
wheel

# Try compatible flash-attn version first
# flash-attn>=2.6.0,<2.8.0 --no-build-isolation

# Fallback option - remove flash_attn and rely on xformers
# Comment out flash_attn line above if using this approach

# Model and tokenizer utilities
tokenizers>=0.20.3
huggingface-hub>=0.34.0

# File handling
aiofiles==23.2.0

# Logging and monitoring
loguru==0.7.2

# Configuration
pydantic==2.5.0
pydantic-settings==2.1.0

# Development and debugging
rich==13.7.0

# HTTP client for model downloads
httpx==0.25.2
requests==2.31.0

# Audio codecs and processing
resampy==0.4.2
audioread==3.0.1

# Memory optimization
psutil==5.9.6

# Additional utilities for video generation
matplotlib==3.8.2
seaborn==0.13.0

# ONNX runtime (optional, for optimized inference)
# onnxruntime-gpu==1.16.3

# TensorBoard for monitoring (optional)
tensorboard==2.15.1

# Memory efficient attention
# xformers==0.0.23.post1

# Additional image utilities
scikit-image==0.22.0
easydict
ftfy
dashscope
gradio>=5.0.0
xfuser>=0.4.1
pyloudnorm
optimum-quanto==0.2.6
scenedetect
decord
